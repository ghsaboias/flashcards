#!/usr/bin/env python3
"""
Seed character_connections table from hsk_network_data.json

Converts the 3,194 links from the JSON network data into D1 INSERT statements.
Handles semantic, compound, and radical connection types.
"""

import json
import sys
from pathlib import Path

def escape_sql(text):
    """Escape single quotes for SQL"""
    if text is None:
        return "NULL"
    return text.replace("'", "''")

def main():
    # Load JSON from frontend public directory
    json_path = Path(__file__).parent.parent / 'frontend' / 'public' / 'hsk_network_data.json'

    if not json_path.exists():
        print(f"Error: {json_path} not found", file=sys.stderr)
        sys.exit(1)

    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    links = data.get('links', [])

    print("-- Seed character_connections from hsk_network_data.json")
    print(f"-- Total links: {len(links)}")
    print("-- Generated: Auto-generated by seed_character_connections.py")
    print()
    print("-- Clear existing Chinese domain connections")
    print("DELETE FROM character_connections WHERE domain_id = 'chinese';")
    print()

    # Track connection types for validation and deduplicate
    stats = {'semantic': 0, 'compound': 0, 'radical': 0, 'phonetic': 0, 'duplicates_skipped': 0}
    seen = set()

    for i, link in enumerate(links, 1):
        # Deduplicate based on (source, target, type)
        dedup_key = (link['source'], link['target'], link['type'])
        if dedup_key in seen:
            stats['duplicates_skipped'] += 1
            continue
        seen.add(dedup_key)
        source = escape_sql(link['source'])
        target = escape_sql(link['target'])
        conn_type = link['type']
        strength = link.get('strength', 1.0)

        # Handle compound_word field (may be 'compound' or 'compound_word' in JSON)
        compound_word = link.get('compound') or link.get('compound_word')
        compound_sql = f"'{escape_sql(compound_word)}'" if compound_word else "NULL"

        stats[conn_type] = stats.get(conn_type, 0) + 1

        print(f"INSERT INTO character_connections (domain_id, source_char, target_char, connection_type, strength, compound_word)")
        print(f"VALUES ('chinese', '{source}', '{target}', '{conn_type}', {strength}, {compound_sql});")

        # Progress marker every 500 rows
        if i % 500 == 0:
            print(f"-- Progress: {i}/{len(links)} ({i*100//len(links)}%)")
            print()

    print()
    print("-- Seeding complete")
    print(f"-- Statistics:")
    print(f"--   Total processed: {len(links)}")
    print(f"--   Unique inserted: {len(seen)}")
    print(f"--   Duplicates skipped: {stats['duplicates_skipped']}")
    for conn_type in ['semantic', 'compound', 'radical', 'phonetic']:
        count = stats.get(conn_type, 0)
        if count > 0:
            print(f"--   {conn_type}: {count}")

if __name__ == '__main__':
    main()
